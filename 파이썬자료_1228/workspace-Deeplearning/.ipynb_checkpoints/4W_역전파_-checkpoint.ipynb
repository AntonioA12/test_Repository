{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mnist import load_mnist\n",
    "\n",
    "(x_train , t_train) , ( x_test , t_test) = load_mnist (normalize=True , one_hot_label = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "t_train.shape\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미니배치 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4985, 37504,  6586, 24567, 35841, 13640, 48567,  7015, 31931,\n",
       "         963])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "\n",
    "batch_mask = np.random.choice( train_size , batch_size )\n",
    "\n",
    "batch_mask\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "\n",
    "x_batch\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차엔트로피 오차 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import cross_entropy_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 텐서 대응\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two layer deep learning architecture 구현하기\n",
    "\n",
    "import numpy as np\n",
    "from layers import *\n",
    "from gradient import numerical_gradient\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TwoLayerNet:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params={}\n",
    "        self.params['W1']=weight_init_std*np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1']=np.zeros(hidden_size)\n",
    "        self.params['W2']=weight_init_std*np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2']=np.zeros(output_size)\n",
    "        \n",
    "        # Affine () \n",
    "        self.layers=OrderedDict()\n",
    "        self.layers['Affine1']=Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu']=Relu()\n",
    "        self.layers['Affine2']=Affine(self.params['W2'], self.params['b2'])\n",
    "        \n",
    "        self.lastlayer=SoftmaxWithLoss()\n",
    "        \n",
    "        \n",
    "        # Affine 값을 forward(x) 한다 \n",
    "        # self.layers.values() = Affine\n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values():\n",
    "            x=layer.forward(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "        # predict 값을 손실함수 사용 \n",
    "        \n",
    "    def loss(self, x, t):\n",
    "        y=self.predict(x)\n",
    "        return self.lastlayer.forward(y,t)\n",
    "    \n",
    "        # 결과값 출력 방식  1 이면 ? 0(or-1) 이면 ?\n",
    "    def accuracy(self,x,t):\n",
    "        y=self.predict(x)\n",
    "        y=np.argmax(y, axis=1)\n",
    "        if t.ndim !=1 : t=np.argmax(t, axis=1)\n",
    "            \n",
    "        accuracy=np.sum(y == t)/float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    # 경사하강법 (dw)\n",
    "    def numerical_gradient(self, x,t):\n",
    "        loss_W=lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads={}\n",
    "        grads['W1']=numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1']=numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2']=numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2']=numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    # 오차역전파\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        #forward\n",
    "        self.loss(x,t)\n",
    "        #backward\n",
    "        dout=1 # 마지막값 Z \n",
    "        dout=self.lastlayer.backward(dout)\n",
    "        \n",
    "        # layers 는 Affine  \n",
    "        # layers 에 list 화 하여 W 값 넣기 \n",
    "        \n",
    "        # layer 수 만큼 backword()로 편미분 \n",
    "        # 편미분된 dout 값을 지속적으로 편미분 \n",
    "        # ( =  dout = layer.backward(dout) ) \n",
    "        \n",
    "        # 따라서 모든 편미분값  = dout \n",
    "        \n",
    "        # Affine class 보면 dout = dW \n",
    "        layers=list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout=layer.backward(dout)\n",
    "            \n",
    "        grads={}\n",
    "        # dout = dW 임.\n",
    "        # dW  = 업데이트룰 로 grads 로 출력 \n",
    "        grads['W1'], grads['b1']=self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2']=self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09988333333333334 0.0994\n",
      "0.9016 0.9075\n",
      "0.9233333333333333 0.9243\n",
      "0.9349166666666666 0.935\n",
      "0.9455333333333333 0.9435\n",
      "0.9511166666666667 0.9488\n",
      "0.9557833333333333 0.9523\n",
      "0.9604666666666667 0.9566\n",
      "0.9643333333333334 0.9612\n",
      "0.9653333333333334 0.9619\n",
      "0.96825 0.9631\n",
      "0.9709833333333333 0.9639\n",
      "0.9738 0.9646\n",
      "0.97325 0.966\n",
      "0.9765833333333334 0.9678\n",
      "0.9784 0.968\n",
      "0.9782833333333333 0.9691\n"
     ]
    }
   ],
   "source": [
    "## 학습 및 실행\n",
    "\n",
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test)=load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network=TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num=10000\n",
    "train_size=x_train.shape[0]\n",
    "batch_size=100\n",
    "learning_rate=0.1\n",
    "\n",
    "train_loss_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "\n",
    "iter_per_epoch=max(train_size/batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask=np.random.choice(train_size, batch_size)\n",
    "    x_batch=x_train[batch_mask]\n",
    "    t_batch=t_train[batch_mask]\n",
    "    \n",
    "    # 오차역전파를 이용하여 기울기 계산\n",
    "    \n",
    "    grad=network.gradient(x_batch, t_batch) \n",
    "    \n",
    "    # 가중치 업데이트\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        \n",
    "    loss =network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc=network.accuracy(x_train, t_train)\n",
    "        test_acc=network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "        print(train_acc, test_acc)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35810582  0.42012936 -0.19795103 -0.04888804  0.20891777  0.32133481\n",
      " -0.16912143  0.16439903 -0.31297253 -0.02774213]\n"
     ]
    }
   ],
   "source": [
    "print(network.params['b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
